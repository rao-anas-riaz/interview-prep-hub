import { QuestionCategory } from '../types';

const powerBICategory: QuestionCategory = {
    id: 'power_bi',
    title: 'Power BI',
    icon: 'fa-chart-bar',
    description: 'Comprehensive questions on Power BI, from data modeling and DAX to visualization and performance optimization.',
    questions: [
      {
        id: 'pbi-1',
        question: 'What is the Power BI ecosystem? Describe the roles of Power BI Desktop, Service, and Mobile, and compare the three main data connectivity modes.',
        concepts: '**Power BI Ecosystem**: The suite of tools for data analysis, including Desktop (development), Service (collaboration/sharing), and Mobile (viewing).\n**Data Connectivity Modes**: Import, DirectQuery, and Live Connection, which determine how Power BI interacts with data sources.',
        answer: 'The Power BI ecosystem consists of three core components that work together:\n- **Power BI Desktop**: A free, Windows-based application used for development. This is where you connect to data, transform it in Power Query, create a data model, and design reports with visuals.\n- **Power BI Service**: A cloud-based (SaaS) service where reports are published for sharing and collaboration. It handles dashboards, security (like RLS), scheduled data refreshes, and app distribution.\n- **Power BI Mobile**: Native apps for phones and tablets used to securely view and interact with published reports and dashboards.\n\nThere are three main ways to connect to data:\n- **Import Mode**: This is the default and most performant mode. Power BI loads a compressed, in-memory copy of the data. All visuals query this internal copy, making it very fast. Data is refreshed on a schedule.\n- **DirectQuery Mode**: Power BI connects directly to the source database. No data is imported. When a user interacts with a report, Power BI sends live queries to the source. This is for very large datasets that won\'t fit in memory or when near real-time data is required.\n- **Live Connection**: A specific type of DirectQuery that connects to an analysis model (like SQL Server Analysis Services or a Power BI dataset). It\'s similar to DirectQuery but connects to a pre-built model instead of a raw database.',
        example: 'You would use **Import Mode** for a 1-million-row sales CSV file. You would use **DirectQuery** for a 1-billion-row transaction table in a SQL database. You would use **Live Connection** to connect to an existing corporate data warehouse cube that already has defined measures and logic.'
      },
      {
        id: 'pbi-2',
        question: 'Explain the core principles of data modeling in Power BI, including relationships, cardinality, and the difference between a star and snowflake schema.',
        concepts: '**Data Modeling**: The process of structuring tables and relationships to support efficient and accurate analysis.\n**Star Schema**: A modeling approach with a central fact table and surrounding, de-normalized dimension tables.\n**Snowflake Schema**: An extension of a star schema where dimension tables are normalized into multiple related tables.',
        answer: 'Effective data modeling is the foundation of a good Power BI report.\n- **Relationships**: These define how tables are connected, typically on a key column (e.g., `ProductID`). They allow filters to propagate from one table to another.\n- **Cardinality**: Describes the uniqueness of values in a column within a relationship (One-to-One, One-to-Many, Many-to-Many). One-to-Many is the most common and ideal type.\n\nTwo common schema designs are:\n- **Star Schema**: This is the recommended design for Power BI. It consists of a central **Fact Table** (containing quantitative business measurements like `Sales Amount`) and several **Dimension Tables** connected to it (containing descriptive attributes like `Product`, `Customer`, `Date`). The structure looks like a star. It is simple, easy to understand, and performs very well.\n- **Snowflake Schema**: This is a more normalized version of a star schema. A dimension table is broken down into further tables. For example, a `Product` dimension might be snowflaked into `Product`, `ProductSubcategory`, and `ProductCategory` tables. This saves storage space but makes the model more complex and can lead to slower performance due to more joins.',
        example: 'A classic **Star Schema**: a `FactSales` table in the center connected to `DimProduct`, `DimCustomer`, and `DimDate`. If you were to normalize `DimProduct` by creating a separate `DimProductCategory` table linked to it, the model would become a **Snowflake Schema**.'
      },
      {
        id: 'pbi-3',
        question: 'What is the difference between a calculated column and a measure in DAX? When should you use each?',
        concepts: '**Calculated Column**: A new column added to a table, with its values computed row-by-row during data refresh. It is physically stored in the model.\n**Measure**: A formula that is calculated on-the-fly at query time, based on the user\'s current context (filters, slicers). It is not stored in the model.',
        answer: 'This is a fundamental concept in DAX:\n- **Calculated Column**:\n  - **Computed**: During data refresh.\n  - **Stored**: In the model, consumes RAM.\n  - **Context**: Operates in **Row Context**. It can only see the values in the current row it is calculating.\n  - **Use When**: You need to create a static label for each row, or when you want to use the result as a slicer, filter, or in an axis of a visual.\n\n- **Measure**:\n  - **Computed**: At query time (when a visual renders).\n  - **Stored**: Not stored, consumes CPU at query time.\n  - **Context**: Operates in **Filter Context**. It can see the entire data model filtered by the user\'s selections.\n  - **Use When**: You need to calculate an aggregation (like sum, average, count) that responds dynamically to user interactions.',
        example: '**Calculated Column Example**: Creating a `Price Tier` column on a Products table: `Price Tier = IF(Products[Price] > 100, "High", "Low")`. This value is fixed for each product.\n**Measure Example**: Calculating total sales: `Total Sales = SUM(Sales[SaleAmount])`. This value changes dynamically as you filter by year, region, or product category.'
      },
      {
        id: 'pbi-4',
        question: 'Explain the concept of "context" in DAX. How do row context and filter context differ, and how does the CALCULATE function manipulate them?',
        concepts: '**Filter Context**: The set of active filters applied to the data model from visuals, slicers, or other measures. It is the "environment" a measure is calculated in.\n**Row Context**: An iterator that evaluates an expression for each row of a given table.\n**CALCULATE**: The most powerful function in DAX, used to modify the filter context.',
        answer: 'Context is the environment in which a DAX formula is evaluated. There are two main types:\n- **Filter Context**: This is the "outside" context created by user selections in the report. When you click on "2023" in a slicer, you create a filter context of `Year = 2023` for all measures.\n- **Row Context**: This is an "inside" context that iterates row-by-row through a table. It is created by functions like `SUMX`, `FILTER`, or by calculated columns. In a row context, you can refer to values from the current row.\n\nThe **`CALCULATE`** function is the bridge between them. It is the only function that can modify the filter context. It can:\n1.  **Add new filters**: `CALCULATE(SUM(Sales[Amount]), Products[Color] = "Red")`\n2.  **Override existing filters**: If the user has "Blue" selected, the above formula will ignore it and calculate for "Red".\n3.  **Remove filters**: `CALCULATE(SUM(Sales[Amount]), ALL(Products))` will calculate sales for all products, ignoring any product filters.',
        example: 'Imagine a table visual showing Sales by Country. The filter context for the "USA" row is `Country = "USA"`. If you use `SUMX(Sales, Sales[Price] * Sales[Quantity])`, the `SUMX` function creates a row context, iterating through the `Sales` table (already filtered for USA) one row at a time to perform the multiplication.'
      },
      {
        id: 'pbi-5',
        question: 'How do you write common time-intelligence calculations in DAX, such as Year-to-Date (YTD) or running totals?',
        concepts: '**Time Intelligence**: A collection of DAX functions for analyzing data over time periods.\n**Date Table**: A mandatory prerequisite for time intelligence, a table with a continuous sequence of dates.',
        answer: 'To perform time-intelligence calculations, you must have a dedicated **Date table** marked as such in your model. This table should have a continuous range of dates and be related to your fact tables.\n\n- **Year-to-Date (YTD)**: The easiest way is with the built-in `TOTALYTD` function. It calculates the cumulative sum of a value from the beginning of the year to the current date in the filter context.\n- **Running Total**: This requires a more explicit `CALCULATE` formula. You calculate the measure you want, but modify the filter context to include all dates up to and including the current date.',
        example: '---CODE_START---dax\n-- Year-to-Date Sales\nYTD Sales = TOTALYTD(SUM(Sales[SaleAmount]), \'Date\'[Date])\n\n-- Running Total of Sales\nRunning Total Sales = \nCALCULATE(\n    SUM(Sales[SaleAmount]),\n    FILTER(\n        ALLSELECTED(\'Date\'[Date]),\n        \'Date\'[Date] <= MAX(\'Date\'[Date])\n    )\n)\n---CODE_END---'
      },
      {
        id: 'pbi-6',
        question: 'What is Power Query used for? Explain the difference between merging and appending queries.',
        concepts: '**Power Query**: The data extraction and transformation (ETL) engine in Power BI.\n**M Language**: The functional programming language that records the steps in Power Query.\n**Append vs. Merge**: Two primary ways to combine tables.',
        answer: 'Power Query is the tool used for connecting to data sources and performing data transformations before the data is loaded into the model. Every cleaning step you perform in the UI (like removing columns, filtering rows, or changing data types) is recorded as a line of code in the **M language**.\n\nTwo common ways to combine queries are:\n- **Append**: This stacks rows from two or more tables that have the same (or similar) column structure. It is equivalent to a `UNION ALL` in SQL.\n- **Merge**: This joins two tables based on a common column, creating a wider table with columns from both. It is equivalent to a `JOIN` in SQL (and you can choose the join type: inner, left outer, etc.).',
        example: 'If you have separate tables for `January_Sales` and `February_Sales`, you would **Append** them to create a single sales table for the year. If you have a `Sales` table with a `ProductID` and a `Products` table with product details, you would **Merge** them to bring the `ProductName` and `Category` into the sales table.'
      },
      {
        id: 'pbi-7',
        question: 'How do you create interactive and user-friendly reports? Discuss features like slicers, bookmarks, and drill-through.',
        concepts: '**Interactivity**: Features that allow users to explore and filter data dynamically.\n**Storytelling**: Guiding users through a data narrative using report features.',
        answer: 'Creating an interactive report allows users to answer their own questions and explore the data. Key features include:\n- **Slicers**: On-canvas visual filters (like buttons or dropdowns) that make it easy for users to filter the entire report page by a specific dimension (e.g., year, region).\n- **Cross-filtering/Highlighting**: By default, clicking on a data point in one visual will filter or highlight all other visuals on the page.\n- **Bookmarks**: This powerful feature allows you to save a specific state of a report page (including filters, slicer selections, and visual visibility). You can link buttons to bookmarks to create a guided tour or a story for your users.\n- **Drill-through**: This allows you to create a "destination" page with detailed information. Users can right-click a data point on a summary visual (e.g., a specific product on a bar chart) and "drill through" to the detail page, which will be automatically filtered for that specific product.',
        example: 'A summary page shows total sales by country. A user can click "Canada" on the map, then right-click and **drill-through** to a "Customer Details" page. This detail page will then show a table of all individual customers and their sales, but only for Canada.'
      },
      {
        id: 'pbi-8',
        question: 'What are the key strategies for optimizing the performance of a Power BI report?',
        concepts: '**Performance Optimization**: A set of techniques to make reports load faster and visuals render more quickly.\n**Performance Analyzer**: A Power BI tool that records the query time for each visual.\n**Data Model Size**: A primary driver of performance.',
        answer: 'Optimizing performance is crucial for user adoption. Key strategies include:\n1.  **Optimize the Data Model**: This is the most important step. Use a star schema, remove unnecessary columns and rows, and set correct data types to reduce model size.\n2.  **Write Efficient DAX**: Prefer measures over calculated columns for complex logic. Use variables (`VAR`) within your DAX formulas to store intermediate calculations and avoid re-calculating them.\n3.  **Limit Visuals**: Each visual on a page sends at least one query. Reduce the number of visuals and avoid using high-cardinality fields (e.g., a slicer with thousands of distinct values).\n4.  **Use the Performance Analyzer**: Use this tool in Power BI Desktop to identify which visuals or DAX queries are taking the longest to load, then focus your optimization efforts there.\n5.  **Choose the Right Connection Mode**: Import mode is fastest. If you must use DirectQuery, ensure the source database is highly optimized with proper indexing.\n6.  **Use Aggregations**: For very large DirectQuery datasets, you can create pre-aggregated summary tables in Power BI. This allows most summary-level visuals to query the small, fast aggregation table instead of the massive underlying table.',
        example: 'Using the **Performance Analyzer**, you find that a table visual is taking 10 seconds to load. You realize it is displaying a `TransactionID` column with millions of unique values. By removing this unnecessary high-cardinality column from the visual, the load time drops to under a second.'
      },
      {
        id: 'pbi-9',
        question: 'How do you implement Row-Level Security (RLS) in Power BI?',
        concepts: '**Row-Level Security (RLS)**: A feature for restricting data access for different users within the same report.\n**Roles**: Groups of users that share the same data access rules.\n**DAX Filter Expressions**: The rules that define what data a role can see.',
        answer: 'Row-Level Security (RLS) allows you to share the same report with different users while ensuring they only see the data they are authorized to see. The process involves two main steps:\n1.  **In Power BI Desktop**: \n    - Go to the Modeling tab and select "Manage Roles".\n    - Create a new role (e.g., "Regional_Manager").\n    - For that role, select a table to filter and write a DAX expression that returns a true/false condition. This expression will be applied as a permanent filter for users in that role.\n\n2.  **In Power BI Service**:\n    - After publishing the report, go to the security settings of the dataset.\n    - Find the role you created ("Regional_Manager") and add the email addresses of the users who should be in that role.',
        example: 'To create a role where a sales representative can only see their own data, you could create a role called "SalesRep" and apply a DAX filter on the `Employees` table like: `[EmailAddress] = USERPRINCIPALNAME()`. The `USERPRINCIPALNAME()` function dynamically returns the email of the user viewing the report, effectively filtering the data just for them.'
      },
      {
        id: 'pbi-10',
        question: 'Describe a challenging Power BI project you\'ve worked on using the STAR method.',
        concepts: '**STAR Method**: A structured way to answer behavioral questions (Situation, Task, Action, Result).\n**Problem Solving**: Demonstrating your ability to diagnose issues, develop a plan, and execute it.',
        answer: 'This is a behavioral question, so you should structure your answer using the STAR method to tell a clear and concise story.\n- **S (Situation)**: Describe the business context and the problem. What was wrong? E.g., "A client had a critical sales report that took over two minutes to load, and users complained the data was often inaccurate."\n- **T (Task)**: State your specific responsibility. What were you asked to do? E.g., "My task was to diagnose the performance and data quality issues, optimize the report, and validate the numbers."\n- **A (Action)**: Detail the steps you took. This should be the longest part of your answer. E.g., "First, I used the Performance Analyzer to identify the slowest visuals. Then, I examined the data model and found it was a flat table with many redundant columns. I restructured the model into a star schema, separating sales facts from product and customer dimensions. I used Power Query to clean the data and replaced several complex calculated columns with efficient DAX measures."\n- **R (Result)**: Quantify the outcome and its business impact. E.g., "By optimizing the model and DAX, the report load time decreased from 2 minutes to under 5 seconds. I also added a validation page that reconciled the report totals with the source system, which increased stakeholder trust in the data. This led to a 50% increase in report usage by the sales team."',
        example: 'Use the structure above to frame a personal project experience. Focus on demonstrating a systematic approach to problem-solving and always link your technical actions to a measurable business outcome.'
      },
      {
        id: 'pbi-11',
        question: 'If your data source schema changes (like a new column is added, removed, or renamed), how will you handle it in Power Query?',
        concepts: '**Schema Drift**: Changes in the structure of data at the source.\n**Resiliency**: Designing queries that don\'t break when non-critical changes occur.\n**Advanced Editor**: Directly modifying the M code to handle dynamic schemas.',
        answer: 'Handling schema changes requires a robust Power Query design strategy:\n1.  **Avoid Hardcoding Columns**: Standard steps like "Changed Type" often hardcode every column name. Deleting or renaming a column in the source will break this step. To fix this, you can remove the hardcoded list from the M code or use `Table.TransformColumnTypes` dynamically.\n2.  **Use `Table.ColumnNames`**: If you need to perform an operation on "all other columns" (like unpivoting), fetch the column names dynamically instead of selecting them by name.\n3.  **`MissingField.Ignore`**: When selecting records or columns, you can use the optional `MissingField.Ignore` parameter. This tells Power Query to proceed even if a specific column is missing, rather than throwing an error.\n4.  **Unpivot**: Unpivoting data is a great way to handle new attribute columns. If a new "Month" column is added to a wide dataset, an unpivot step will automatically pick it up and turn it into a row value without any code changes.',
        example: 'If you have a source with columns `[ID, Name, Jan_Sales, Feb_Sales]`, and next month `Mar_Sales` is added, a standard query might ignore it. By selecting `ID` and `Name` and choosing "Unpivot Other Columns", your query will automatically ingest `Mar_Sales` data without any maintenance.'
      },
      {
        id: 'pbi-12',
        question: 'Write a DAX measure for 2-Month Growth Rate.',
        concepts: '**Time Intelligence**: Using DAX to compare data across different time periods.\n**CALCULATE & DATEADD**: Shifting the filter context to a previous date.\n**Variables (VAR)**: Making code cleaner and more performant.',
        answer: 'To calculate a 2-month growth rate, you need to compare current sales with sales from two months ago.\n\n1.  **Calculate Current Sales**: `SUM(Sales[Amount])`.\n2.  **Calculate Past Sales**: Use `CALCULATE` with `DATEADD` to shift the context back by 2 months.\n3.  **Calculate Growth**: Subtract past from current, and divide by past. Using `DIVIDE` is safer than `/` as it handles division by zero gracefully.',
        example: '---CODE_START---dax\n2-Month Growth Rate = \nVAR CurrentSales = SUM(Sales[Amount])\nVAR Sales2MonthsAgo = \n    CALCULATE(\n        SUM(Sales[Amount]), \n        DATEADD(\'Date\'[Date], -2, MONTH)\n    )\n\nRETURN\n    DIVIDE(CurrentSales - Sales2MonthsAgo, Sales2MonthsAgo)\n---CODE_END---'
      },
      {
        id: 'pbi-13',
        question: 'What is Incremental Refresh vs. Scheduled Refresh?',
        concepts: '**Scheduled Refresh**: Reloading the entire dataset at set intervals.\n**Incremental Refresh**: Reloading only the data that has changed or is new.\n**Partitioning**: Power BI manages partitions behind the scenes for incremental refresh.',
        answer: 'These are two strategies for keeping data up-to-date:\n- **Scheduled Refresh (Full Refresh)**: This creates a completely new snapshot of the data. Power BI deletes all existing data in the dataset and re-imports everything from the source. This is simple but becomes inefficient and slow as data grows.\n- **Incremental Refresh**: Power BI creates partitions for the table. It keeps older historical partitions (e.g., 5 years of data) static and only refreshes the latest partition (e.g., the last 10 days). This makes refreshes much faster, more reliable, and reduces the load on the source system.',
        example: 'For a retailer with 10 years of transaction history, a **Scheduled Refresh** might take 2 hours to reload 100 million rows every night. With **Incremental Refresh**, the initial load takes 2 hours, but subsequent daily refreshes might take only 5 minutes because they only process the new transactions from the current day.'
      },
      {
        id: 'pbi-14',
        question: 'How do you solve Many-to-Many relationship issues for better data accuracy?',
        concepts: '**Many-to-Many**: A relationship where a value can appear multiple times in both joined tables.\n**Bridge Table (Junction Table)**: An intermediate table containing unique keys used to link two many-to-many tables.\n**Ambiguity**: Many-to-many relationships can introduce ambiguity in filter propagation.',
        answer: 'Direct Many-to-Many relationships in Power BI (using the "Both" cross-filter direction) can be risky. They often lead to ambiguous paths and unexpected filtering results.\n\n**The Best Practice Solution**: Use a **Bridge Table**.\n1.  Identify the common entity (e.g., `Student` and `Class` are Many-to-Many because a student takes many classes and a class has many students).\n2.  Create a distinct intermediate table (e.g., `Enrollments`) that contains the unique combinations of keys from both sides.\n3.  Create One-to-Many relationships from the original tables to the bridge table.\n\nThis converts the unstable Many-to-Many relationship into two standard, stable One-to-Many relationships.',
        example: 'If you have `Sales` and `Budget` tables, both at a `Month` granularity (Many-to-Many via Date), you should not link them directly. Instead, link both `Sales` and `Budget` to a shared `DimDate` table using One-to-Many relationships. Filter the `DimDate` table to filter both facts accurately.'
      },
      {
        id: 'pbi-15',
        question: 'What distinguishes a KPI (Key Performance Indicator) from a dimension?',
        concepts: '**KPI**: A measurable value that demonstrates how effectively a company is achieving key business objectives.\n**Dimension**: A descriptive attribute or characteristic of data used for filtering, grouping, and labeling.',
        answer: 'They serve different purposes in data analysis:\n- **KPI (Metric)**: It is a quantitative value (a number) that is compared against a target. It answers "How much?" or "How well?". Examples: Total Sales, Customer Satisfaction Score, Churn Rate.\n- **Dimension**: It is a qualitative attribute (text or category) that provides context to the numbers. It answers "Who?", "Where?", or "When?". Examples: Product Category, Region, Month, Employee Name.\n\nYou slice a KPI *by* a Dimension (e.g., "Total Sales" by "Region").',
        example: 'In a sales report, **$1,000,000** is the **KPI** (Sales Amount). **"North America"** and **"Q1 2023"** are the **Dimensions** used to break down that number.'
      },
      {
        id: 'pbi-16',
        question: 'Can you explain how you would create a DAX measure in Power BI to calculate the year-over-year growth for a specific metric?',
        concepts: '**Time Intelligence**, **SAMEPERIODLASTYEAR**, **DIVIDE**. Calculating growth requires comparing a current metric to a past metric.',
        answer: 'To calculate Year-over-Year (YoY) growth, you need three components:\n1.  **Current Value**: The base measure (e.g., `[Total Sales]`).\n2.  **Previous Year Value**: Use `CALCULATE` with `SAMEPERIODLASTYEAR` to get the value for the corresponding period in the previous year.\n3.  **Growth Calculation**: Find the difference and divide by the previous year\'s value.\n\nDAX:\n`YoY Growth = DIVIDE([Total Sales] - [Sales LY], [Sales LY])`\nWhere `[Sales LY] = CALCULATE([Total Sales], SAMEPERIODLASTYEAR(\'Date\'[Date]))`.',
        example: 'If Sales in 2023 were $120 and Sales in 2022 were $100:\n- Sales LY = $100\n- Difference = $20\n- Growth = 20 / 100 = 20%'
      },
      {
        id: 'pbi-17',
        question: 'Identify a unique chart type in Power BI that differs from standard charts and explain its purpose.',
        concepts: '**AI Visuals**, **Decomposition Tree**, **Key Influencers**. Power BI offers advanced visuals beyond simple bars and lines.',
        answer: 'The **Decomposition Tree** is a unique, AI-powered visual that allows for ad-hoc root cause analysis.\n\nUnlike standard charts where the axis is fixed, the Decomposition Tree lets users interactively choose how to drill down into a measure. It breaks down a value (like Total Sales) by various dimensions (like Region, Product, Person) in a tree-like structure.\n\nIt also has an "AI split" feature where you can ask it to automatically find the dimension that generates the "High" or "Low" values, helping you find patterns you didn\'t know to look for.',
        example: 'If Total Sales are down, you can use a Decomposition Tree to break Sales down. You might first click "Region" and see "West" is low. Then, within "West", you click "Product Category" and see "Electronics" is the culprit. It lets you traverse the data hierarchy dynamically.'
      },
      {
        id: 'pbi-18',
        question: 'Describe how you would implement a time intelligence feature in Power BI to analyze sales trends over different time periods.',
        concepts: '**Date Table**, **DATESYTD**, **DATESMTD**, **DATESQTD**. Implementing flexible time analysis.',
        answer: 'Implementing robust time intelligence requires a dedicated **Date Table** linked to your fact table.\n\n1.  **Date Table**: Ensure you have a continuous date table (no missing days) marked as a "Date table" in the model.\n2.  **Measures**: Create measures using DAX time intelligence functions.\n    - **YTD**: `CALCULATE(SUM(Sales[Amount]), DATESYTD(\'Date\'[Date]))`\n    - **QTD**: `CALCULATE(SUM(Sales[Amount]), DATESQTD(\'Date\'[Date]))`\n    - **MTD**: `CALCULATE(SUM(Sales[Amount]), DATESMTD(\'Date\'[Date]))`\n3.  **Visualization**: Use a matrix visual with the Date hierarchy (Year > Quarter > Month) on rows and these measures on columns to allow users to drill down and see trends across different grains.',
        example: 'By setting up `Sales YTD` and `Sales Previous Year` measures, a user can easily see that while monthly sales might fluctuate, the Year-to-Date trend is consistently 5% higher than last year.'
      }
    ],
};

export default powerBICategory;