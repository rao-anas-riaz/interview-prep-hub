import { QuestionCategory } from '../types';

const powerBICategory: QuestionCategory = {
    id: 'power_bi',
    title: 'Power BI',
    icon: 'fa-chart-bar',
    description: 'Comprehensive questions on Power BI, from data modeling and DAX to visualization and performance optimization.',
    questions: [
      {
        id: 'pbi-1',
        question: 'What is the Power BI ecosystem? Describe the roles of Power BI Desktop, Service, and Mobile, and compare the three main data connectivity modes.',
        concepts: '**Power BI Ecosystem**: The suite of tools for data analysis, including Desktop (development), Service (collaboration/sharing), and Mobile (viewing).\n**Data Connectivity Modes**: Import, DirectQuery, and Live Connection, which determine how Power BI interacts with data sources.',
        answer: 'The Power BI ecosystem consists of three core components that work together:\n- **Power BI Desktop**: A free, Windows-based application used for development. This is where you connect to data, transform it in Power Query, create a data model, and design reports with visuals.\n- **Power BI Service**: A cloud-based (SaaS) service where reports are published for sharing and collaboration. It handles dashboards, security (like RLS), scheduled data refreshes, and app distribution.\n- **Power BI Mobile**: Native apps for phones and tablets used to securely view and interact with published reports and dashboards.\n\nThere are three main ways to connect to data:\n- **Import Mode**: This is the default and most performant mode. Power BI loads a compressed, in-memory copy of the data. All visuals query this internal copy, making it very fast. Data is refreshed on a schedule.\n- **DirectQuery Mode**: Power BI connects directly to the source database. No data is imported. When a user interacts with a report, Power BI sends live queries to the source. This is for very large datasets that won\'t fit in memory or when near real-time data is required.\n- **Live Connection**: A specific type of DirectQuery that connects to an analysis model (like SQL Server Analysis Services or a Power BI dataset). It\'s similar to DirectQuery but connects to a pre-built model instead of a raw database.',
        example: 'You would use **Import Mode** for a 1-million-row sales CSV file. You would use **DirectQuery** for a 1-billion-row transaction table in a SQL database. You would use **Live Connection** to connect to an existing corporate data warehouse cube that already has defined measures and logic.'
      },
      {
        id: 'pbi-2',
        question: 'Explain the core principles of data modeling in Power BI, including relationships, cardinality, and the difference between a star and snowflake schema.',
        concepts: '**Data Modeling**: The process of structuring tables and relationships to support efficient and accurate analysis.\n**Star Schema**: A modeling approach with a central fact table and surrounding, de-normalized dimension tables.\n**Snowflake Schema**: An extension of a star schema where dimension tables are normalized into multiple related tables.',
        answer: 'Effective data modeling is the foundation of a good Power BI report.\n- **Relationships**: These define how tables are connected, typically on a key column (e.g., `ProductID`). They allow filters to propagate from one table to another.\n- **Cardinality**: Describes the uniqueness of values in a column within a relationship (One-to-One, One-to-Many, Many-to-Many). One-to-Many is the most common and ideal type.\n\nTwo common schema designs are:\n- **Star Schema**: This is the recommended design for Power BI. It consists of a central **Fact Table** (containing quantitative business measurements like `Sales Amount`) and several **Dimension Tables** connected to it (containing descriptive attributes like `Product`, `Customer`, `Date`). The structure looks like a star. It is simple, easy to understand, and performs very well.\n- **Snowflake Schema**: This is a more normalized version of a star schema. A dimension table is broken down into further tables. For example, a `Product` dimension might be snowflaked into `Product`, `ProductSubcategory`, and `ProductCategory` tables. This saves storage space but makes the model more complex and can lead to slower performance due to more joins.',
        example: 'A classic **Star Schema**: a `FactSales` table in the center connected to `DimProduct`, `DimCustomer`, and `DimDate`. If you were to normalize `DimProduct` by creating a separate `DimProductCategory` table linked to it, the model would become a **Snowflake Schema**.'
      },
      {
        id: 'pbi-3',
        question: 'What is the difference between a calculated column and a measure in DAX? When should you use each?',
        concepts: '**Calculated Column**: A new column added to a table, with its values computed row-by-row during data refresh. It is physically stored in the model.\n**Measure**: A formula that is calculated on-the-fly at query time, based on the user\'s current context (filters, slicers). It is not stored in the model.',
        answer: 'This is a fundamental concept in DAX:\n- **Calculated Column**:\n  - **Computed**: During data refresh.\n  - **Stored**: In the model, consumes RAM.\n  - **Context**: Operates in **Row Context**. It can only see the values in the current row it is calculating.\n  - **Use When**: You need to create a static label for each row, or when you want to use the result as a slicer, filter, or in an axis of a visual.\n\n- **Measure**:\n  - **Computed**: At query time (when a visual renders).\n  - **Stored**: Not stored, consumes CPU at query time.\n  - **Context**: Operates in **Filter Context**. It can see the entire data model filtered by the user\'s selections.\n  - **Use When**: You need to calculate an aggregation (like sum, average, count) that responds dynamically to user interactions.',
        example: '**Calculated Column Example**: Creating a `Price Tier` column on a Products table: `Price Tier = IF(Products[Price] > 100, "High", "Low")`. This value is fixed for each product.\n**Measure Example**: Calculating total sales: `Total Sales = SUM(Sales[SaleAmount])`. This value changes dynamically as you filter by year, region, or product category.'
      },
      {
        id: 'pbi-4',
        question: 'Explain the concept of "context" in DAX. How do row context and filter context differ, and how does the CALCULATE function manipulate them?',
        concepts: '**Filter Context**: The set of active filters applied to the data model from visuals, slicers, or other measures. It is the "environment" a measure is calculated in.\n**Row Context**: An iterator that evaluates an expression for each row of a given table.\n**CALCULATE**: The most powerful function in DAX, used to modify the filter context.',
        answer: 'Context is the environment in which a DAX formula is evaluated. There are two main types:\n- **Filter Context**: This is the "outside" context created by user selections in the report. When you click on "2023" in a slicer, you create a filter context of `Year = 2023` for all measures.\n- **Row Context**: This is an "inside" context that iterates row-by-row through a table. It is created by functions like `SUMX`, `FILTER`, or by calculated columns. In a row context, you can refer to values from the current row.\n\nThe **`CALCULATE`** function is the bridge between them. It is the only function that can modify the filter context. It can:\n1.  **Add new filters**: `CALCULATE(SUM(Sales[Amount]), Products[Color] = "Red")`\n2.  **Override existing filters**: If the user has "Blue" selected, the above formula will ignore it and calculate for "Red".\n3.  **Remove filters**: `CALCULATE(SUM(Sales[Amount]), ALL(Products))` will calculate sales for all products, ignoring any product filters.',
        example: 'Imagine a table visual showing Sales by Country. The filter context for the "USA" row is `Country = "USA"`. If you use `SUMX(Sales, Sales[Price] * Sales[Quantity])`, the `SUMX` function creates a row context, iterating through the `Sales` table (already filtered for USA) one row at a time to perform the multiplication.'
      },
      {
        id: 'pbi-5',
        question: 'How do you write common time-intelligence calculations in DAX, such as Year-to-Date (YTD) or running totals?',
        concepts: '**Time Intelligence**: A collection of DAX functions for analyzing data over time periods.\n**Date Table**: A mandatory prerequisite for time intelligence, a table with a continuous sequence of dates.',
        answer: 'To perform time-intelligence calculations, you must have a dedicated **Date table** marked as such in your model. This table should have a continuous range of dates and be related to your fact tables.\n\n- **Year-to-Date (YTD)**: The easiest way is with the built-in `TOTALYTD` function. It calculates the cumulative sum of a value from the beginning of the year to the current date in the filter context.\n- **Running Total**: This requires a more explicit `CALCULATE` formula. You calculate the measure you want, but modify the filter context to include all dates up to and including the current date.',
        example: '---CODE_START---dax\n-- Year-to-Date Sales\nYTD Sales = TOTALYTD(SUM(Sales[SaleAmount]), \'Date\'[Date])\n\n-- Running Total of Sales\nRunning Total Sales = \nCALCULATE(\n    SUM(Sales[SaleAmount]),\n    FILTER(\n        ALLSELECTED(\'Date\'[Date]),\n        \'Date\'[Date] <= MAX(\'Date\'[Date])\n    )\n)\n---CODE_END---'
      },
      {
        id: 'pbi-6',
        question: 'What is Power Query used for? Explain the difference between merging and appending queries.',
        concepts: '**Power Query**: The data extraction and transformation (ETL) engine in Power BI.\n**M Language**: The functional programming language that records the steps in Power Query.\n**Append vs. Merge**: Two primary ways to combine tables.',
        answer: 'Power Query is the tool used for connecting to data sources and performing data transformations before the data is loaded into the model. Every cleaning step you perform in the UI (like removing columns, filtering rows, or changing data types) is recorded as a line of code in the **M language**.\n\nTwo common ways to combine queries are:\n- **Append**: This stacks rows from two or more tables that have the same (or similar) column structure. It is equivalent to a `UNION ALL` in SQL.\n- **Merge**: This joins two tables based on a common column, creating a wider table with columns from both. It is equivalent to a `JOIN` in SQL (and you can choose the join type: inner, left outer, etc.).',
        example: 'If you have separate tables for `January_Sales` and `February_Sales`, you would **Append** them to create a single sales table for the year. If you have a `Sales` table with a `ProductID` and a `Products` table with product details, you would **Merge** them to bring the `ProductName` and `Category` into the sales table.'
      },
      {
        id: 'pbi-7',
        question: 'How do you create interactive and user-friendly reports? Discuss features like slicers, bookmarks, and drill-through.',
        concepts: '**Interactivity**: Features that allow users to explore and filter data dynamically.\n**Storytelling**: Guiding users through a data narrative using report features.',
        answer: 'Creating an interactive report allows users to answer their own questions and explore the data. Key features include:\n- **Slicers**: On-canvas visual filters (like buttons or dropdowns) that make it easy for users to filter the entire report page by a specific dimension (e.g., year, region).\n- **Cross-filtering/Highlighting**: By default, clicking on a data point in one visual will filter or highlight all other visuals on the page.\n- **Bookmarks**: This powerful feature allows you to save a specific state of a report page (including filters, slicer selections, and visual visibility). You can link buttons to bookmarks to create a guided tour or a story for your users.\n- **Drill-through**: This allows you to create a "destination" page with detailed information. Users can right-click a data point on a summary visual (e.g., a specific product on a bar chart) and "drill through" to the detail page, which will be automatically filtered for that specific product.',
        example: 'A summary page shows total sales by country. A user can click "Canada" on the map, then right-click and **drill-through** to a "Customer Details" page. This detail page will then show a table of all individual customers and their sales, but only for Canada.'
      },
      {
        id: 'pbi-8',
        question: 'What are the key strategies for optimizing the performance of a Power BI report?',
        concepts: '**Performance Optimization**: A set of techniques to make reports load faster and visuals render more quickly.\n**Performance Analyzer**: A Power BI tool that records the query time for each visual.\n**Data Model Size**: A primary driver of performance.',
        answer: 'Optimizing performance is crucial for user adoption. Key strategies include:\n1.  **Optimize the Data Model**: This is the most important step. Use a star schema, remove unnecessary columns and rows, and set correct data types to reduce model size.\n2.  **Write Efficient DAX**: Prefer measures over calculated columns for complex logic. Use variables (`VAR`) within your DAX formulas to store intermediate calculations and avoid re-calculating them.\n3.  **Limit Visuals**: Each visual on a page sends at least one query. Reduce the number of visuals and avoid using high-cardinality fields (e.g., a slicer with thousands of distinct values).\n4.  **Use the Performance Analyzer**: Use this tool in Power BI Desktop to identify which visuals or DAX queries are taking the longest to load, then focus your optimization efforts there.\n5.  **Choose the Right Connection Mode**: Import mode is fastest. If you must use DirectQuery, ensure the source database is highly optimized with proper indexing.\n6.  **Use Aggregations**: For very large DirectQuery datasets, you can create pre-aggregated summary tables in Power BI. This allows most summary-level visuals to query the small, fast aggregation table instead of the massive underlying table.',
        example: 'Using the **Performance Analyzer**, you find that a table visual is taking 10 seconds to load. You realize it is displaying a `TransactionID` column with millions of unique values. By removing this unnecessary high-cardinality column from the visual, the load time drops to under a second.'
      },
      {
        id: 'pbi-9',
        question: 'How do you implement Row-Level Security (RLS) in Power BI?',
        concepts: '**Row-Level Security (RLS)**: A feature for restricting data access for different users within the same report.\n**Roles**: Groups of users that share the same data access rules.\n**DAX Filter Expressions**: The rules that define what data a role can see.',
        answer: 'Row-Level Security (RLS) allows you to share the same report with different users while ensuring they only see the data they are authorized to see. The process involves two main steps:\n1.  **In Power BI Desktop**: \n    - Go to the Modeling tab and select "Manage Roles".\n    - Create a new role (e.g., "Regional_Manager").\n    - For that role, select a table to filter and write a DAX expression that returns a true/false condition. This expression will be applied as a permanent filter for users in that role.\n\n2.  **In Power BI Service**:\n    - After publishing the report, go to the security settings of the dataset.\n    - Find the role you created ("Regional_Manager") and add the email addresses of the users who should be in that role.',
        example: 'To create a role where a sales representative can only see their own data, you could create a role called "SalesRep" and apply a DAX filter on the `Employees` table like: `[EmailAddress] = USERPRINCIPALNAME()`. The `USERPRINCIPALNAME()` function dynamically returns the email of the user viewing the report, effectively filtering the data just for them.'
      },
      {
        id: 'pbi-10',
        question: 'Describe a challenging Power BI project you\'ve worked on using the STAR method.',
        concepts: '**STAR Method**: A structured way to answer behavioral questions (Situation, Task, Action, Result).\n**Problem Solving**: Demonstrating your ability to diagnose issues, develop a plan, and execute it.',
        answer: 'This is a behavioral question, so you should structure your answer using the STAR method to tell a clear and concise story.\n- **S (Situation)**: Describe the business context and the problem. What was wrong? E.g., "A client had a critical sales report that took over two minutes to load, and users complained the data was often inaccurate."\n- **T (Task)**: State your specific responsibility. What were you asked to do? E.g., "My task was to diagnose the performance and data quality issues, optimize the report, and validate the numbers."\n- **A (Action)**: Detail the steps you took. This should be the longest part of your answer. E.g., "First, I used the Performance Analyzer to identify the slowest visuals. Then, I examined the data model and found it was a flat table with many redundant columns. I restructured the model into a star schema, separating sales facts from product and customer dimensions. I used Power Query to clean the data and replaced several complex calculated columns with efficient DAX measures."\n- **R (Result)**: Quantify the outcome and its business impact. E.g., "By optimizing the model and DAX, the report load time decreased from 2 minutes to under 5 seconds. I also added a validation page that reconciled the report totals with the source system, which increased stakeholder trust in the data. This led to a 50% increase in report usage by the sales team."',
        example: 'Use the structure above to frame a personal project experience. Focus on demonstrating a systematic approach to problem-solving and always link your technical actions to a measurable business outcome.'
      }
    ],
};

export default powerBICategory;